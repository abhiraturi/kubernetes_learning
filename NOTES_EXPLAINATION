Replication controller/replica set:
Replication controller (replica set is the newer version, use replicates instead of replication controller now)
So,  with replicates you can manage the already running pods under the replicates using labels


deployment:
Deployment manages replicates and replicates manages pods. Deployment provides extra functionality.
e.g. if we want to upgrade image of nginx, if you do it using replicas set you will face downtime.
So, deployment makes changes in rolling manner, so there is no downtime.
Deployment creates  the replicaset and the replicaset creates the pods
So, if you want to change the image, you can do from below ways
Kubectl set image deploy/nginx-deploy nginx=nginx:1.9.1
Or directly edit the yaml file and apply 
Or directly update the deploy yaml manifest using command -> kubectl edit deployment/nginx-deploy



services:
We want to access this nginx frontend external, this can be done using services.
So, to make the application accessible to users and also to make the sure that the frontend pods are able to communicate with backend pods and external data sources we use services.

Users -> service -> frontend pods -> service -> backend pods -> service -> database

There are 4 types of services:
  - NodePort
  - ClusterIP
  - LoadBalancer
  - ExternalName

A NodePort service is a way to expose a service on a specific port on each node in the cluster. This port is called the NodePort. Traffic sent to the NodePort is forwarded to the service.
A ClusterIP service is the default type of service. It gives a service an IP address that is only accessible from within the cluster. This is useful for services that only need to be accessed by other applications within the cluster.
A LoadBalancer service is a way to expose a service externally. It creates a load balancer in the cloud provider and forwards traffic to the service.
A ExternalName service is a way to map a service to a DNS name. This is useful for services that are not hosted in Kubernetes.


Namespce:
Here are some notes about the video, Day 10/40 - Kubernetes Namespace Explained - CKA Full Course 2025:
 * Namespaces:  Provide a way to isolate resources within a Kubernetes cluster.
 * Default Namespace: When you create a resource without specifying a namespace, it goes into the "default" namespace.
 * Other Namespaces: Kubernetes creates namespaces like "kube-system" for its own components.
 * Resource Management: Namespaces make it easier to manage resources by grouping them logically.
 * Security: You can assign different permissions (RBAC) to different namespaces.
 * Communication: Resources within the same namespace can communicate with each other using their hostnames.
 * Cross-Namespace Communication:  Pods in different namespaces need to use fully qualified domain names (FQDNs) to communicate.
 * Creating Namespaces: You can create namespaces using kubectl create ns <namespace-name>.
 * Deleting Namespaces: You can delete namespaces using kubectl delete ns <namespace-name>.
 * Working with Namespaces: When working with resources in a specific namespace, you need to specify the namespace using the -n flag with kubectl commands.
 * Services: Services can be used to expose deployments to other namespaces.
 * Accessing Services: To access a service in another namespace, you need to use its FQDN.
 * FQDN Format: The FQDN for a service is typically <service-name>.<namespace-name>.svc.cluster.local.
 * ETC resolve conf: This file on the pod is responsible for IP to DNS resolution and shows how to construct the FQDN.
Additional Notes:
 * The video includes a demo showing how to create namespaces, deploy pods, expose services, and test communication between pods in different namespaces.
 * The instructor emphasizes the importance of practice for the CKA exam.
 * The video is part of a larger CKA course.
I hope these notes are helpful!




Multi containers:
This video is about multi-container pods in Kubernetes.
The speaker first introduces the concept of multi-container pods, which allow you to have multiple containers running in a single pod. This can be useful for a variety of reasons, such as separating application code from helper processes or running multiple processes that need to communicate with each other. The speaker then explains the two types of multi-container pods: init containers and sidecar containers. Init containers are containers that run before the main application container and are used to perform initialization tasks, such as setting up environment variables or creating configuration files. Sidecar containers are containers that run alongside the main application container and provide additional services, such as logging or monitoring.
The speaker then gives a demo of how to create a multi-container pod using an init container. The init container in the demo is used to wait for a service to be available before starting the main application container. The speaker also shows how to use environment variables in a multi-container pod.
Finally, the speaker gives a brief overview of the next video in the series, which will cover demon sets and cron jobs.



Daemonset:
This video is about Kubernetes Daemonset, Jobs, and Cronjobs.
Kubernetes Daemonset ensures that all nodes run a copy of a pod. It is often used for monitoring, logging, and networking. Some control plane components and networking components are deployed as Daemonsets. The video shows how to create a Daemonset.
Jobs are used for tasks that run one time and then complete. Cronjobs are used for tasks that need to be run on a schedule. The video shows how to create a Cronjob.
The video also includes a small assignment task in the GitHub repository.


Static pods/manual scheduling:
scheduler does not manage static pod but kubelet manages the static pods.
Pods can be scheduled manually by mentioning the node in the pods yaml file. So, even if the scheduler is down, the pods will still be scheduled in the node mentioned in the yaml file.
generally, the scheduler, api server, controller manager, etc yamls are under /etc/kubernetes/manifest directory in control plane node, these are called static pods.
This video is about scheduling and selecting pods in Kubernetes. The video starts with an introduction of the Kubernetes architecture and the role of the scheduler in assigning pods to nodes. The video then introduces the concept of static pods, which are control plane components that are not managed by the scheduler. The video also covers manual scheduling, which allows users to specify the node on which a pod should be scheduled. Finally, the video discusses labels and selectors, which are used to filter and group resources in Kubernetes.


taints and tolerations, labels, selectors:
We are instructing node to only accept specific pod that has the tolerations.
e.g. we want to run AI pod on a specific node because that node has specifications to run the AI workload. SO based on tolerations matching the AI pods will be acepted by node and rest of the other pods will be rejected and scheduled on dfifferent node.
Taint is done on node and toleration is done on pods.

types:
noschedule : works only for newer pods
noexecute: works for all existing and newer pods
prefernoschedule: no guarantee of pods scheduling for the taint and tolerations.

selector:
We add the label on node and pod, so it will schedule the pod to those nodes that has same labels. So, it will not go to the node that does not have matching labels as that of the pod.
So, taints and tolerations is to avoid the nodes but labels and selector tells which pod will be scheduled on what node.

Node Affinity:
It can have multiple labels attached to nodes e.g. disk in (ssd,hdd) which is not possible in taints and tolerations.

types:
1. requiredDuringSchedulingIgnoredDuringExecution
the labels must match otherwise pods will not be schduled, pods will get stuck in pending state if affinity does not match.
If pur node is priority that a pod needs to be scheduled on a specific node then go with this.

2. preferredDuringSchedulingIgnoredDuringExecution
first check the labels , if matches schedule the pod otherwise just schedule the pod. If pod is out priority i.e. the pod must be scheduled irrespective of affinity matching or not, then use this.



Autoscaling:
Autoscaling:
Application with 1000 of pods, its not possible to scale manually.
Based on resources utillization we can autoscale.

HPA: horizontal pod Autoscaling. Also called scale out/sclae in
This will add identical pods on deployment based on load in the server based on cpu, memory.
There are more users, it will add more replicas. We are adding pods horizontally and automatically.
This can be applied on two different aspects 1. infra i.e. nodes 2. worklloads i.e. pods

VPA: vertical pod automatically
Increase the pod size instead of adding. The pod will be replaced by bigger pod. stateless in nature, downtime will be there.
This can be applied on two different aspects 1. infra i.e. nodes 2. worklloads i.e. pods

Event based autoscaling (keda)

Only hpa comes as default as part of kubernetes.

