Replication controller/replica set:
Replication controller (replica set is the newer version, use replicates instead of replication controller now)
So,  with replicates you can manage the already running pods under the replicates using labels


deployment:
Deployment manages replicates and replicates manages pods. Deployment provides extra functionality.
e.g. if we want to upgrade image of nginx, if you do it using replicas set you will face downtime.
So, deployment makes changes in rolling manner, so there is no downtime.
Deployment creates  the replicaset and the replicaset creates the pods
So, if you want to change the image, you can do from below ways
Kubectl set image deploy/nginx-deploy nginx=nginx:1.9.1
Or directly edit the yaml file and apply 
Or directly update the deploy yaml manifest using command -> kubectl edit deployment/nginx-deploy



services:
We want to access this nginx frontend external, this can be done using services.
So, to make the application accessible to users and also to make the sure that the frontend pods are able to communicate with backend pods and external data sources we use services.

Users -> service -> frontend pods -> service -> backend pods -> service -> database

There are 4 types of services:
  - NodePort
  - ClusterIP
  - LoadBalancer
  - ExternalName

A NodePort service is a way to expose a service on a specific port on each node in the cluster. This port is called the NodePort. Traffic sent to the NodePort is forwarded to the service.
A ClusterIP service is the default type of service. It gives a service an IP address that is only accessible from within the cluster. This is useful for services that only need to be accessed by other applications within the cluster.
A LoadBalancer service is a way to expose a service externally. It creates a load balancer in the cloud provider and forwards traffic to the service.
A ExternalName service is a way to map a service to a DNS name. This is useful for services that are not hosted in Kubernetes.


Namespce:
Here are some notes about the video, Day 10/40 - Kubernetes Namespace Explained - CKA Full Course 2025:
 * Namespaces:  Provide a way to isolate resources within a Kubernetes cluster.
 * Default Namespace: When you create a resource without specifying a namespace, it goes into the "default" namespace.
 * Other Namespaces: Kubernetes creates namespaces like "kube-system" for its own components.
 * Resource Management: Namespaces make it easier to manage resources by grouping them logically.
 * Security: You can assign different permissions (RBAC) to different namespaces.
 * Communication: Resources within the same namespace can communicate with each other using their hostnames.
 * Cross-Namespace Communication:  Pods in different namespaces need to use fully qualified domain names (FQDNs) to communicate.
 * Creating Namespaces: You can create namespaces using kubectl create ns <namespace-name>.
 * Deleting Namespaces: You can delete namespaces using kubectl delete ns <namespace-name>.
 * Working with Namespaces: When working with resources in a specific namespace, you need to specify the namespace using the -n flag with kubectl commands.
 * Services: Services can be used to expose deployments to other namespaces.
 * Accessing Services: To access a service in another namespace, you need to use its FQDN.
 * FQDN Format: The FQDN for a service is typically <service-name>.<namespace-name>.svc.cluster.local.
 * ETC resolve conf: This file on the pod is responsible for IP to DNS resolution and shows how to construct the FQDN.
Additional Notes:
 * The video includes a demo showing how to create namespaces, deploy pods, expose services, and test communication between pods in different namespaces.
 * The instructor emphasizes the importance of practice for the CKA exam.
 * The video is part of a larger CKA course.
I hope these notes are helpful!




Multi containers:
This video is about multi-container pods in Kubernetes.
The speaker first introduces the concept of multi-container pods, which allow you to have multiple containers running in a single pod. This can be useful for a variety of reasons, such as separating application code from helper processes or running multiple processes that need to communicate with each other. The speaker then explains the two types of multi-container pods: init containers and sidecar containers. Init containers are containers that run before the main application container and are used to perform initialization tasks, such as setting up environment variables or creating configuration files. Sidecar containers are containers that run alongside the main application container and provide additional services, such as logging or monitoring.
The speaker then gives a demo of how to create a multi-container pod using an init container. The init container in the demo is used to wait for a service to be available before starting the main application container. The speaker also shows how to use environment variables in a multi-container pod.
Finally, the speaker gives a brief overview of the next video in the series, which will cover demon sets and cron jobs.



Daemonset:
This video is about Kubernetes Daemonset, Jobs, and Cronjobs.
Kubernetes Daemonset ensures that all nodes run a copy of a pod. It is often used for monitoring, logging, and networking. Some control plane components and networking components are deployed as Daemonsets. The video shows how to create a Daemonset.
Jobs are used for tasks that run one time and then complete. Cronjobs are used for tasks that need to be run on a schedule. The video shows how to create a Cronjob.
The video also includes a small assignment task in the GitHub repository.


Static pods/manual scheduling:
scheduler does not manage static pod but kubelet manages the static pods.
Pods can be scheduled manually by mentioning the node in the pods yaml file. So, even if the scheduler is down, the pods will still be scheduled in the node mentioned in the yaml file.
generally, the scheduler, api server, controller manager, etc yamls are under /etc/kubernetes/manifest directory in control plane node, these are called static pods.
This video is about scheduling and selecting pods in Kubernetes. The video starts with an introduction of the Kubernetes architecture and the role of the scheduler in assigning pods to nodes. The video then introduces the concept of static pods, which are control plane components that are not managed by the scheduler. The video also covers manual scheduling, which allows users to specify the node on which a pod should be scheduled. Finally, the video discusses labels and selectors, which are used to filter and group resources in Kubernetes.


taints and tolerations, labels, selectors:
We are instructing node to only accept specific pod that has the tolerations.
e.g. we want to run AI pod on a specific node because that node has specifications to run the AI workload. SO based on tolerations matching the AI pods will be acepted by node and rest of the other pods will be rejected and scheduled on dfifferent node.
Taint is done on node and toleration is done on pods.

types:
noschedule : works only for newer pods
noexecute: works for all existing and newer pods
prefernoschedule: no guarantee of pods scheduling for the taint and tolerations.

selector:
We add the label on node and pod, so it will schedule the pod to those nodes that has same labels. So, it will not go to the node that does not have matching labels as that of the pod.
So, taints and tolerations is to avoid the nodes but labels and selector tells which pod will be scheduled on what node.

Node Affinity:
It can have multiple labels attached to nodes e.g. disk in (ssd,hdd) which is not possible in taints and tolerations.

types:
1. requiredDuringSchedulingIgnoredDuringExecution
the labels must match otherwise pods will not be schduled, pods will get stuck in pending state if affinity does not match.
If pur node is priority that a pod needs to be scheduled on a specific node then go with this.

2. preferredDuringSchedulingIgnoredDuringExecution
first check the labels , if matches schedule the pod otherwise just schedule the pod. If pod is out priority i.e. the pod must be scheduled irrespective of affinity matching or not, then use this.



Autoscaling:
Autoscaling:
Application with 1000 of pods, its not possible to scale manually.
Based on resources utillization we can autoscale.

HPA: horizontal pod Autoscaling. Also called scale out/sclae in
This will add identical pods on deployment based on load in the server based on cpu, memory.
There are more users, it will add more replicas. We are adding pods horizontally and automatically.
This can be applied on two different aspects 1. infra i.e. nodes 2. worklloads i.e. pods

VPA: vertical pod automatically
Increase the pod size instead of adding. The pod will be replaced by bigger pod. stateless in nature, downtime will be there.
This can be applied on two different aspects 1. infra i.e. nodes 2. worklloads i.e. pods

Event based autoscaling (keda)

Only hpa comes as default as part of kubernetes.

Health probes:
Health checks using http/tcp in an interval of time.

Three types:
1. startup probes -> for slow legacy apps. first startup probe will be active and only then readiness and liveness probes gets active.
for production, combination of probes are used.
2. readiness probes -> ensure the application is ready before the application starts serving traffic to the user.
3. liveness probes -> restart the application if it fails
it actually monitors the application, if application fails or crash due to network etc, the liveness probes restarts the pod.

So, when probe fails continuously for sometime, you will see crashloopbackoff for the pod.

Configmap and secrets
When env variable grows, not a good practise to keep in different yaml.
We create configmap and key value inside configmap and inject those inside pods.
best practise is to use volume mount inconfig map.
ConfigMaps and Secrets allow you to store and manage configuration data and sensitive information, such as passwords and API keys, separately from your application code. This makes it easier to update and manage your application's configuration, and it also helps to improve security by keeping sensitive information out of your code.
The video then provides a demo of how to create and use ConfigMaps and Secrets in a Kubernetes cluster. The demo shows how to create a ConfigMap, how to mount a ConfigMap into a Pod, and how to access the data in a ConfigMap from your application. The demo also shows how to create a Secret, how to mount a Secret into a Pod, and how to access the data in a Secret from your application.
The video ends with a discussion of some of the best practices for using ConfigMaps and Secrets in Kubernetes. The discussion covers topics such as how to choose the right type of ConfigMap or Secret for your needs, how to secure your ConfigMaps and Secrets, and how to manage your ConfigMaps and Secrets across different environments.
Overall, this video provides a good overview of Kubernetes ConfigMaps and Secrets. The video is clear and concise, and the demo is well-done. If you are interested in learning more about Kubernetes ConfigMaps and Secrets, this video is a good place to start.


TLS/SSL :
The speaker starts with a simple example of a user sending a request to a server. The server asks for authentication details, and the user sends their credentials. However, this communication is not secure and can be intercepted by a hacker.
To secure the communication, the user and server can use encryption. There are two types of encryption: symmetric and asymmetric. In symmetric encryption, the same key is used to encrypt and decrypt the data. In asymmetric encryption, different keys are used for encryption and decryption.
SSL/TLS uses asymmetric encryption to secure the communication between a user and a server. The server generates a public key and a private key. The public key is sent to the user, and the user uses it to encrypt their data. The server then uses the private key to decrypt the data.
To ensure that the user is communicating with the correct server, SSL/TLS uses certificates. A certificate is a digital document that verifies the identity of a server. When a user connects to a server, the server sends its certificate to the user. The user's browser then checks the certificate to make sure that it is valid.

If the certificate is valid, the user's browser will establish a secure connection with the server. This connection is called an HTTPS connection.
The speaker then explains how certificates are issued and signed by certificate authorities (CAs). CAs are trusted organizations that verify the identity of servers.
Finally, the speaker discusses how SSL/TLS works in Kubernetes. Kubernetes is a container orchestration platform. The speaker explains how to create a certificate signing request (CSR) in Kubernetes and how to have it signed by a CA.


This video is about securing communication in Kubernetes clusters using TLS. It explains the basics of TLS and how it works in Kubernetes, including the different types of certificates involved (client, server, and root certificates). The video also covers how to create and approve certificate signing requests (CSRs) and how to share the issued certificates with users. The video provides a detailed walkthrough of the process, with commands and examples. It also emphasizes the importance of practicing these steps for the CKAD exam.